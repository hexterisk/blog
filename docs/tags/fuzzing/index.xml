<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fuzzing on Pwn the world.</title>
    <link>https://hexterisk.github.io/blog/tags/fuzzing/</link>
    <description>Recent content in fuzzing on Pwn the world.</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Sun, 04 Oct 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://hexterisk.github.io/blog/tags/fuzzing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>DART &amp; SAGE</title>
      <link>https://hexterisk.github.io/blog/posts/2020/10/04/dart-sage/</link>
      <pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hexterisk.github.io/blog/posts/2020/10/04/dart-sage/</guid>
      <description>DART Back in 2005, researchers at Microsoft came up with a concolic testing tool called DART(Directed Automated Random Testing). The tool can be used in the unit testing phase, as well as can be applied to large programs.
 We present a new tool, named DART, for automatically testing software that combines three main techniques: (1) automated extraction of the interface of a program with its external environment using static source-code parsing; (2) automatic generation of a test driver for this interface that performs random testing to simulate the most general environment the program can operate in; and (3) dynamic analysis of how the program behaves under random testing and automatic generation of new test inputs to direct systematically the execution along alternative program paths.</description>
    </item>
    
    <item>
      <title>Architecture</title>
      <link>https://hexterisk.github.io/blog/posts/2020/09/16/architecture/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hexterisk.github.io/blog/posts/2020/09/16/architecture/</guid>
      <description>A robust pipeline needs to be established to ensure that a fuzzer is effective and efficient. The pipeline is required to perform the following tasks:
 Generate new test cases. Ensure delivery of the test cases to, and safe execution, of the target. Record the statistics from the execution of the test cases. Reproduce the crashes. Triage the crashes.  Generic fuzzing pipeline.
Separate modules perform different set of the aforementioned tasks.</description>
    </item>
    
    <item>
      <title>Approaches</title>
      <link>https://hexterisk.github.io/blog/posts/2020/09/09/approaches/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hexterisk.github.io/blog/posts/2020/09/09/approaches/</guid>
      <description>Fuzzing can be segregated into different types based on the facet of the process we look at.
 Program Structure Knowledge of the internals of the target application directly results into maintaining a certain structure to the fuzzing process, which can result into achieving a higher code coverage in a shorter span of time. This results in a much more effective fuzzing exercise.
Blackbox Fuzzing This approach involves the assumption that the target is a black box since we don&amp;rsquo;t have any knowledge of the internal behavior, source code or the implementation of the target application, hence the name.</description>
    </item>
    
    <item>
      <title>Introduction</title>
      <link>https://hexterisk.github.io/blog/posts/2020/09/05/introduction/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hexterisk.github.io/blog/posts/2020/09/05/introduction/</guid>
      <description>Fuzzing, or Fuzz Testing, is an automated software testing technique where a target application is placed in an execution environment. An input generation technique is employed to create unique and varying inputs(test cases) for the target. These new inputs are continuously sent to the target and the resultant behavior is observed.
NOTE: the phrases “test cases” and “inputs” can be used interchangeably.
Fuzzing cycle.
Either the program will be able to handle the provided input just fine, or it will enter an invalid state of execution(mostly a crash) and you&amp;rsquo;ll have a bug report on your hand.</description>
    </item>
    
  </channel>
</rss>
